{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import binascii\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/all_news.pkl\", 'rb') as f:\n",
    "    news = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shingles(words, n=2):\n",
    "    for i in range (0,len(words)-n+1):\n",
    "        yield ' '.join(words[i:i+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(source):\n",
    "    stop_symbols = '.,!?:;-\\n\\r()—'\n",
    "\n",
    "    stop_words = ('это', 'как', 'так',\n",
    "                  'и', 'в', 'над',\n",
    "                  'к', 'до', 'не',\n",
    "                  'на', 'но', 'за',\n",
    "                  'то', 'с', 'ли',\n",
    "                  'а', 'во', 'от',\n",
    "                  'со', 'для', 'о',\n",
    "                  'же', 'ну', 'вы',\n",
    "                  'бы', 'что', 'кто',\n",
    "                  'он', 'она')\n",
    "\n",
    "    return ( [x for x in [y.strip(stop_symbols) for y in source.lower().split()] if x and (x not in stop_words)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 20016/20016 [00:14<00:00, 1417.88it/s]\n"
     ]
    }
   ],
   "source": [
    "shingle_sets = {}\n",
    "all_shingles = set()\n",
    "i = 0\n",
    "for document in tqdm(news):\n",
    "    shingles_in_doc = set()\n",
    "    clean_doc = clean(document['body'])\n",
    "    shingles = {i for i in get_shingles(clean_doc, 5)}\n",
    "    for shingle in shingles:\n",
    "        crc = binascii.crc32(shingle.encode('utf-8')) & 0xffffffff\n",
    "        shingles_in_doc.add(crc)\n",
    "        all_shingles.add(crc)\n",
    "    \n",
    "    shingle_sets[i] = shingles_in_doc\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shingles = list(all_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_num = len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = np.zeros((docs_num, docs_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(docs_num)):\n",
    "    doc_1 = shingle_sets[i]\n",
    "    for j in range(i+1, docs_num):\n",
    "        doc_2 = shingle_sets[j]\n",
    "        sim_matrix[i][j] = len(doc_1.intersection(doc_2)) / len(doc_1.union(doc_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hashes = 15\n",
    "sim_matrix = np.zeros((docs_num, docs_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_hashes():\n",
    "    new_list = []\n",
    "    for i in range(num_hashes):\n",
    "        r = random.sample(all_shingles, len(all_shingles))\n",
    "        new_list.append(r)\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hash(matrix, shingles):\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i] in shingles:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = build_new_hashes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 20016/20016 [26:34<00:00, 12.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(docs_num)):\n",
    "    signature = []\n",
    "    shingles_set = shingle_sets[i]\n",
    "    \n",
    "    for m in hashes:\n",
    "        cur_hash = calculate_hash(m, shingles_set)\n",
    "        signature.append(cur_hash)\n",
    "        \n",
    "    signatures.append(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 20016/20016 [23:46<00:00, 14.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(docs_num)):\n",
    "    signature1 = signatures[i]\n",
    "    for j in range(i + 1, docs_num):\n",
    "        signature2 = signatures[j]\n",
    "            \n",
    "        count = 0\n",
    "        for k in range(0, num_hashes):\n",
    "            count += signature1[k] == signature2[k]\n",
    "\n",
    "        sim_matrix[i][j] = (count / num_hashes)\n",
    "        sim_matrix[j][i] = (count / num_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59509,\n",
       " 13047,\n",
       " 654,\n",
       " 6926,\n",
       " 37214,\n",
       " 39352,\n",
       " 13891,\n",
       " 30094,\n",
       " 24278,\n",
       " 31159,\n",
       " 22092,\n",
       " 6818,\n",
       " 14694,\n",
       " 42717,\n",
       " 5328]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9846,\n",
       " 18711,\n",
       " 42654,\n",
       " 29611,\n",
       " 20673,\n",
       " 4693,\n",
       " 9932,\n",
       " 446,\n",
       " 2984,\n",
       " 34328,\n",
       " 2309,\n",
       " 24075,\n",
       " 1372,\n",
       " 14236,\n",
       " 22056]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for j in range(i + 1, docs_num):\n",
    "    estJ = sim_matrix[i][j]\n",
    "    \n",
    "    if estJ > threshold:\n",
    "        print(j)\n",
    "        print(news[j]['body'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
